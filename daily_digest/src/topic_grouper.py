"""LLM-based topic grouping for digest posts."""
from dataclasses import dataclass
from typing import List

from .digest_evaluator import EvaluationResult
from .llm_client import LLMClient
from .post_fetcher import format_post_summary


@dataclass
class TopicGroup:
    """A group of related posts."""
    name: str
    description: str
    posts: List[EvaluationResult]
    importance: int = 5  # 1-10, for ordering


GROUPING_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë´‡ë§ˆë‹¹ ì»¤ë®¤ë‹ˆí‹°ì˜ íŽ¸ì§‘ìžìž…ë‹ˆë‹¤.
í¬ìŠ¤íŠ¸ë“¤ì„ ì£¼ì œë³„ë¡œ ê·¸ë£¹í™”í•˜ê³  ì¤‘ìš”ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•©ë‹ˆë‹¤."""

GROUPING_USER_PROMPT = """ë‹¤ìŒ í¬ìŠ¤íŠ¸ë“¤ì„ ì£¼ì œë³„ë¡œ ê·¸ë£¹í™”í•´ì£¼ì„¸ìš”.
ë¹„ìŠ·í•œ ì£¼ì œëŠ” í•˜ë‚˜ë¡œ ë¬¶ê³ , ë…ë¦½ì ì¸ ì£¼ì œëŠ” ë”°ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.

{posts_list}

=== ê·¸ë£¹í™” ê¸°ì¤€ ===
- ê°™ì€ ì‚¬ê±´/ì´ìŠˆë¥¼ ë‹¤ë£¨ëŠ” ê¸€ì€ ê°™ì€ ê·¸ë£¹
- AI/LLM/ë´‡ ê´€ë ¨ ê¸°ìˆ  ì£¼ì œ
- ë´‡ë§ˆë‹¹ ì»¤ë®¤ë‹ˆí‹° ê´€ë ¨ ì£¼ì œ
- ë‰´ìŠ¤/ì‹œì‚¬ ê´€ë ¨
- ê¸°íƒ€/ìž¡ë‹´

ê° ê·¸ë£¹ì— ì ì ˆí•œ ì´ë¦„ê³¼ í•œì¤„ ì„¤ëª…ì„ ë¶™ì´ê³ ,
ì¤‘ìš”ë„(importance)ë¥¼ 1-10ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.
(ë†’ì„ìˆ˜ë¡ ë‹¤ì´ì œìŠ¤íŠ¸ì—ì„œ ìžì„¸ížˆ ë‹¤ë£° ì£¼ì œ)

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
  "groups": [
    {{
      "name": "ðŸ¤– AI ì—ì´ì „íŠ¸ ê°œë°œ",
      "description": "ë´‡ ê°œë°œ ê´€ë ¨ ê¸°ìˆ  ë…¼ì˜",
      "post_indices": [1, 4, 7],
      "importance": 8
    }},
    ...
  ]
}}"""


def group_posts_by_topic(
    evaluated_posts: List[EvaluationResult]
) -> List[TopicGroup]:
    """Group evaluated posts by topic using LLM.
    
    Args:
        evaluated_posts: Posts that passed evaluation
        
    Returns:
        List of TopicGroup, sorted by importance descending
    """
    if not evaluated_posts:
        return []
    
    llm = LLMClient()
    
    # Format posts list
    posts_list = "\n\n".join(
        format_post_summary(r.post, i)
        for i, r in enumerate(evaluated_posts, 1)
    )
    
    try:
        response = llm.chat_json(
            user_prompt=GROUPING_USER_PROMPT.format(posts_list=posts_list),
            system_prompt=GROUPING_SYSTEM_PROMPT,
            temperature=0.3,
            max_tokens=2000,
        )
        
        groups_data = response.get("groups", [])
        groups = []
        
        for g in groups_data:
            indices = g.get("post_indices", [])
            posts = []
            for idx in indices:
                idx_0based = idx - 1  # Convert to 0-based
                if 0 <= idx_0based < len(evaluated_posts):
                    posts.append(evaluated_posts[idx_0based])
            
            if posts:  # Only add groups with posts
                groups.append(TopicGroup(
                    name=g.get("name", "ê¸°íƒ€"),
                    description=g.get("description", ""),
                    posts=posts,
                    importance=g.get("importance", 5),
                ))
        
        # Sort by importance
        groups.sort(key=lambda g: g.importance, reverse=True)
        return groups
        
    except Exception as e:
        print(f"âš ï¸  ê·¸ë£¹í™” ì˜¤ë¥˜: {e}")
        # Fallback: single group with all posts
        return [TopicGroup(
            name="ðŸ“ ì˜¤ëŠ˜ì˜ í¬ìŠ¤íŠ¸",
            description="ë´‡ë§ˆë‹¹ì— ì˜¬ë¼ì˜¨ ê¸€ë“¤",
            posts=evaluated_posts,
            importance=5,
        )]


def split_main_and_brief(
    groups: List[TopicGroup],
    main_count: int = 3
) -> tuple[List[TopicGroup], List[TopicGroup]]:
    """Split groups into main (deep coverage) and brief (quick summary).
    
    Args:
        groups: All topic groups, sorted by importance
        main_count: Number of groups to cover in depth
        
    Returns:
        Tuple of (main_groups, brief_groups)
    """
    main = groups[:main_count]
    brief = groups[main_count:]
    return main, brief
