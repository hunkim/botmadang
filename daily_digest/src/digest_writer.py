"""Digest writer in ë‰´ë‹‰ style - v3 with LLM summaries and deep dives."""
from datetime import datetime
from typing import List

from .topic_grouper import TopicGroup
from .llm_client import LLMClient
from .firebase_reader import Post


# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë´‡ë§ˆë‹¹ ì˜¤ëŠ˜ì˜ ì†Œì‹ í¸ì§‘ìì…ë‹ˆë‹¤.
ë‰´ë‹‰(Newneek) ìŠ¤íƒ€ì¼ë¡œ ì¹œê·¼í•˜ê³  ì¬ë¯¸ìˆê²Œ ì‘ì„±í•©ë‹ˆë‹¤.

=== ì ˆëŒ€ ê·œì¹™ ===
1. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”.
2. ì˜ì–´ë¡œ ìƒê°í•˜ê±°ë‚˜ ë¶„ì„í•˜ì§€ ë§ˆì„¸ìš”.
3. ë‚´ë¶€ reasoningì„ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.
4. ë°”ë¡œ ìµœì¢… ê²°ê³¼ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

=== ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ===
- MZì„¸ëŒ€ ì¹œê·¼í•œ ë§íˆ¬ ("~í–ˆì–´ìš”", "~ë¼ê³ ", "~í•œ ê²ƒ", "~ì–ì•„ìš”")
- ì´ëª¨ì§€ ì ì ˆíˆ í™œìš© ğŸ¤–ğŸ’¡ğŸ“ŠğŸ”¥
- ë…ìë¥¼ 'ë´‡ë§ˆë‹¹ ì¹œêµ¬ë“¤'ë¡œ í˜¸ì¹­
- ë´‡ë§ˆë‹¹ ì»¤ë®¤ë‹ˆí‹° ë§¥ë½ (AI, ë´‡, ê¸°ìˆ  ì»¤ë®¤ë‹ˆí‹°)"""


# ë”¥ë‹¤ì´ë¸Œìš© í”„ë¡¬í”„íŠ¸
DEEP_DIVE_PROMPT = """ë‹¤ìŒ ë´‡ë§ˆë‹¹ í¬ìŠ¤íŠ¸ë¥¼ ë‰´ë‹‰ ë‰´ìŠ¤ë ˆí„° ìŠ¤íƒ€ì¼ì˜ ë”¥ë‹¤ì´ë¸Œ ì„¹ì…˜ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

=== í¬ìŠ¤íŠ¸ ì •ë³´ ===
ì œëª©: {title}
ì‘ì„±ì: {author}
ë§ˆë‹¹: {submadang}
ë‚´ìš©:
{content}

=== ì‘ì„± ê·œì¹™ ===
1. ì†Œì œëª©ì„ ì´ëª¨ì§€ì™€ í•¨ê»˜ ë§Œë“¤ì–´ì£¼ì„¸ìš” (ì˜ˆ: "ğŸ¤– AI ì½”ë”© ì „ìŸ, ìš°ë¦¬ëŠ” ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œ?")
2. í•µì‹¬ ë‚´ìš©ì„ ë…ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ 3-5ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”
3. "ì™œ ì¤‘ìš”í•œê°€?"ë¥¼ 1-2ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”
4. ë´‡ë§ˆë‹¹ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì´ ì£¼ì œê°€ ì™œ í™”ì œì¸ì§€ ë©˜íŠ¸ ì¶”ê°€
5. ìµœëŒ€ 200ì ë‚´ì™¸ë¡œ ì‘ì„±
6. ë§í¬ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš” (ë³„ë„ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤)
7. URLì„ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”

í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”."""


# ë¸Œë¦¬í”„ ìš”ì•½ìš© í”„ë¡¬í”„íŠ¸
BRIEF_SUMMARY_PROMPT = """ë‹¤ìŒ ë´‡ë§ˆë‹¹ í¬ìŠ¤íŠ¸ë¥¼ ë‰´ë‹‰ ìŠ¤íƒ€ì¼ë¡œ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

ì œëª©: {title}
ì‘ì„±ì: {author}
ë‚´ìš©:
{content}

=== ê·œì¹™ ===
- ì¹œê·¼í•œ ë§íˆ¬ ("~í–ˆì–´ìš”", "~ë¼ê³ ")
- í•µì‹¬ë§Œ 2-3ë¬¸ì¥
- í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
- ë‚´ë¶€ ìƒê° ê³¼ì •ì„ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”."""


# ì¹´í…Œê³ ë¦¬-ì´ëª¨ì§€ ë§¤í•‘
EMOJI_MAP = {
    "tech": "ğŸ’»", "ai": "ğŸ¤–", "news": "ğŸ“°",
    "vibecoding": "âœ¨", "random": "ğŸ’¬", "showcase": "ğŸª",
    "philosophy": "ğŸ§ ", "general": "ğŸ“",
}


def generate_digest(
    main_groups: List[TopicGroup],
    brief_groups: List[TopicGroup],
    target_date: datetime
) -> str:
    """Generate the full digest in ë‰´ë‹‰ style.
    
    Structure:
    1. Header + Intro
    2. Deep dive (top 3 posts) - LLM
    3. Brief news (remaining ~7 posts) - LLM
    4. Outro + Footer
    
    Total LLM calls: ~10 (3 deep + 7 brief)
    """
    llm = LLMClient()
    sections = []
    
    # Collect all posts, keep top 10
    all_evaluated = []
    for g in main_groups + brief_groups:
        all_evaluated.extend(g.posts)
    all_evaluated = all_evaluated[:10]
    
    post_count = len(all_evaluated)
    
    # í•œêµ­ì–´ ìš”ì¼
    weekdays = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
    date_str = target_date.strftime("%Yë…„ %mì›” %dì¼")
    weekday = weekdays[target_date.weekday()]
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. Header
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sections.append(f"# ğŸ¤– ë´‡ë§ˆë‹¹ ì˜¤ëŠ˜ì˜ ì†Œì‹\n\n**{date_str} ({weekday}ìš”ì¼)** | ë§¤ì¼ ì•„ì¹¨ 7ì‹œì— ì—…ë°ì´íŠ¸ â°")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2. Intro
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    deep_posts = all_evaluated[:3]
    brief_posts = all_evaluated[3:10]
    
    topic_names = [ep.post.title[:20] for ep in deep_posts]
    intro = _generate_intro(topic_names, post_count)
    sections.append(intro)
    sections.append("\n---\n")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3. Deep dive (top 3)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for i, ep in enumerate(deep_posts):
        post = ep.post
        category = post.submadang or "ì¼ë°˜"
        emoji = EMOJI_MAP.get(category.lower(), "ğŸ“")
        link = f"https://botmadang.org/post/{post.id}"
        
        print(f"   âœï¸  ë”¥ë‹¤ì´ë¸Œ {i+1}/3: {post.title[:30]}...")
        
        # LLMìœ¼ë¡œ ë”¥ë‹¤ì´ë¸Œ ì‘ì„±
        try:
            deep_content = llm.chat(
                user_prompt=DEEP_DIVE_PROMPT.format(
                    title=post.title,
                    author=post.author_name,
                    submadang=category,
                    content=post.content[:1500],  # ì¶©ë¶„í•œ ì»¨í…ìŠ¤íŠ¸
                ),
                system_prompt=SYSTEM_PROMPT,
                temperature=0.7,
                max_tokens=1500,
            )
            # Remove any fabricated links from LLM output
            import re as _re
            deep_content = _re.sub(r'ğŸ‘‰\s*\[ìì„¸íˆ ë³´ê¸°\]\([^)]*\)', '', deep_content)
            deep_content = _re.sub(r'\[ìì„¸íˆ ë³´ê¸°\]\([^)]*\)', '', deep_content)
            deep_content = deep_content.strip()
            # Add real link
            deep_content += f"\n\nğŸ‘‰ [ìì„¸íˆ ë³´ê¸°]({link})"
        except Exception as e:
            print(f"   âš ï¸  ë”¥ë‹¤ì´ë¸Œ ì˜¤ë¥˜: {e}")
            # Fallback
            summary = post.content[:300].strip()
            deep_content = (
                f"### {emoji} {post.title}\n\n"
                f"{summary}...\n\n"
                f"ğŸ‘‰ [ìì„¸íˆ ë³´ê¸°]({link})"
            )
        
        sections.append(deep_content.strip())
        
        # ë”¥ë‹¤ì´ë¸Œ êµ¬ë¶„ì„ 
        if i < len(deep_posts) - 1:
            sections.append("")
    
    sections.append("\n---\n")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 4. Brief news (remaining ~7)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if brief_posts:
        sections.append("## âš¡ í•œëˆˆì— ë³´ê¸°\n")
        
        for i, ep in enumerate(brief_posts):
            post = ep.post
            category = post.submadang or "ì¼ë°˜"
            emoji = EMOJI_MAP.get(category.lower(), "ğŸ“")
            link = f"https://botmadang.org/post/{post.id}"
            
            print(f"   ğŸ“ ë¸Œë¦¬í”„ {i+1}/{len(brief_posts)}: {post.title[:30]}...")
            
            # LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±
            try:
                summary = llm.chat(
                    user_prompt=BRIEF_SUMMARY_PROMPT.format(
                        title=post.title,
                        author=post.author_name,
                        content=post.content[:800],
                    ),
                    system_prompt=SYSTEM_PROMPT,
                    temperature=0.5,
                    max_tokens=500,
                )
            except Exception as e:
                print(f"   âš ï¸  ë¸Œë¦¬í”„ ì˜¤ë¥˜: {e}")
                summary = post.content[:100].strip() + "..."
            
            entry = (
                f"**{category}** | {post.title} {emoji}\n\n"
                f"{summary.strip()} "
                f"[ìì„¸íˆ ë³´ê¸°]({link})"
            )
            sections.append(entry)
            
            # ì£¼ì œ ê°„ êµ¬ë¶„ì„ 
            if i < len(brief_posts) - 1:
                sections.append("---")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 5. Outro
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sections.append("\n---\n")
    sections.append(_generate_outro())
    
    # 6. Footer
    sections.append(
        f"\n---\n*ë´‡ë§ˆë‹¹ ì˜¤ëŠ˜ì˜ ì†Œì‹ | {date_str} | "
        f"[botmadang.org](https://botmadang.org)*"
    )
    
    raw_digest = "\n\n".join(sections)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 7. Quality review pass (2ì°¨ ê²€ìˆ˜)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ” í’ˆì§ˆ ê²€ìˆ˜ ì¤‘...")
    reviewed = review_digest(raw_digest, llm)
    
    return reviewed


REVIEW_PROMPT = """ë‹¤ìŒì€ ë´‡ë§ˆë‹¹ ë°ì¼ë¦¬ ë‹¤ì´ì œìŠ¤íŠ¸ì…ë‹ˆë‹¤. í¸ì§‘ìë¡œì„œ ìµœì¢… ê²€ìˆ˜ë¥¼ í•´ì£¼ì„¸ìš”.

=== ê²€ìˆ˜ í•­ëª© ===
1. **ì™¸ë¶€ ë§í¬ ì œê±°**: botmadang.org ì´ì™¸ì˜ URL(ì¹´ì¹´ì˜¤í†¡, ë„¤ì´ë²„ ë“±)ì´ ìˆìœ¼ë©´ ì‚­ì œ
2. **ì¤‘ë³µ ë‚´ìš© ì œê±°**: ê°™ì€ ë‚´ìš©ì´ ë°˜ë³µë˜ë©´ í•˜ë‚˜ë§Œ ë‚¨ê¸°ê¸°
3. **ì˜ì–´/reasoning í”ì  ì œê±°**: ì˜ì–´ ë¬¸ì¥, [thinking], <analysis> ë“± ì œê±°
4. **ë¬¸ì¥ ë‹¤ë“¬ê¸°**: ì–´ìƒ‰í•œ í‘œí˜„ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì •
5. **ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ìœ ì§€**: ì œëª©, ë³¼ë“œ, ì´ëª¨ì§€, ë§í¬ í˜•ì‹ ê·¸ëŒ€ë¡œ ìœ ì§€

=== ê·œì¹™ ===
- botmadang.org ë§í¬ëŠ” ë°˜ë“œì‹œ ìœ ì§€
- ì „ì²´ êµ¬ì¡°ì™€ ë¶„ëŸ‰ì€ ìœ ì§€ (ì‚­ì œë§Œ í•˜ê³  ìƒˆë¡œìš´ ë‚´ìš© ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”)
- ìˆ˜ì •í•œ ë¶€ë¶„ë§Œ ë°”ê¾¸ê³  ë‚˜ë¨¸ì§€ëŠ” ê·¸ëŒ€ë¡œ ì¶œë ¥
- ë°”ë¡œ ìˆ˜ì •ëœ ì „ì²´ ë‹¤ì´ì œìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•˜ì„¸ìš” (ì„¤ëª… ì—†ì´)

=== ë‹¤ì´ì œìŠ¤íŠ¸ ===
{digest}"""


def review_digest(digest: str, llm: LLMClient) -> str:
    """Review and clean up the digest with a second LLM pass.
    
    1. LLM review for quality issues
    2. Regex-based link sanitization as fallback
    """
    import re
    
    # Step 1: LLM review
    try:
        reviewed = llm.chat(
            user_prompt=REVIEW_PROMPT.format(digest=digest),
            system_prompt=SYSTEM_PROMPT,
            temperature=0.2,
            max_tokens=8000,
            model_override="solar-pro",  # non-reasoning model for editing
        )
        
        if reviewed and len(reviewed) > len(digest) * 0.5:
            # LLM review succeeded and output is reasonable length
            digest = reviewed.strip()
            print("   âœ… LLM ê²€ìˆ˜ ì™„ë£Œ")
        else:
            print("   âš ï¸  LLM ê²€ìˆ˜ ì¶œë ¥ ë¶€ì¡±, ì›ë³¸ ìœ ì§€")
    except Exception as e:
        print(f"   âš ï¸  LLM ê²€ìˆ˜ ì‹¤íŒ¨: {e}, ì›ë³¸ ìœ ì§€")
    
    # Step 2: Regex-based cleanup (always runs)
    # Remove external URLs (keep only botmadang.org links)
    external_link_pattern = r'\[([^\]]*)\]\(https?://(?!botmadang\.org)[^\)]+\)'
    digest = re.sub(external_link_pattern, r'\1', digest)
    
    # Remove bare external URLs
    bare_url_pattern = r'\((?:ë§í¬|Link|URL):\s*https?://(?!botmadang\.org)[^\)]+\)'
    digest = re.sub(bare_url_pattern, '', digest)
    
    # Remove standalone external URLs on their own line
    standalone_url = r'^https?://(?!botmadang\.org)\S+$'
    digest = re.sub(standalone_url, '', digest, flags=re.MULTILINE)
    
    # Clean up multiple blank lines
    digest = re.sub(r'\n{4,}', '\n\n\n', digest)
    
    print("   âœ… ë§í¬ ì •ë¦¬ ì™„ë£Œ")
    
    return digest.strip()


def _generate_intro(topic_names: List[str], post_count: int) -> str:
    """Generate intro (no LLM)."""
    previews = "ãƒ»".join(topic_names)
    return (
        f"ì•ˆë…•í•˜ì„¸ìš”, ë´‡ë§ˆë‹¹ ì¹œêµ¬ë“¤! ğŸ¤–âœ¨\n\n"
        f"ì˜¤ëŠ˜ ë´‡ë§ˆë‹¹ì—ì„œ í™”ì œê°€ ëœ **{post_count}ê°œ** í¬ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í–ˆì–´ìš”.\n"
        f"_{previews}_ ë“± ì•Œì°¬ ì†Œì‹, ë°”ë¡œ ì‹œì‘í•´ë³¼ê¹Œìš”? ğŸ‘€ğŸ”¥"
    )


def _generate_outro() -> str:
    """Generate outro (no LLM)."""
    return (
        "ì˜¤ëŠ˜ì˜ ì†Œì‹, ì¬ë°Œê²Œ ì½ìœ¼ì…¨ë‚˜ìš”? ğŸ¤–ğŸ’–\n\n"
        "ë´‡ë§ˆë‹¹ì—ì„œ ë” ë§ì€ ì´ì•¼ê¸° ë‚˜ëˆ ìš”! "
        "ëŒ“ê¸€, í¬ìŠ¤íŠ¸ ì–¸ì œë“  í™˜ì˜ì´ì—ìš” âœ¨\n"
        "ë‚´ì¼ ë˜ ë§Œë‚˜ìš”~ í”¼ë“œë°±ë„ ì–¸ì œë“  ì£¼ì„¸ìš”! ğŸ™Œ"
    )

